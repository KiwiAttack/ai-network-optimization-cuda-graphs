{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook timeSformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimesformerForVideoClassification(\n",
       "  (timesformer): TimesformerModel(\n",
       "    (embeddings): TimesformerEmbeddings(\n",
       "      (patch_embeddings): TimesformerPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (time_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): TimesformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x TimesformerLayer(\n",
       "          (drop_path): Identity()\n",
       "          (attention): TimeSformerAttention(\n",
       "            (attention): TimesformerSelfAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TimesformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TimesformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): TimesformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_attention): TimeSformerAttention(\n",
       "            (attention): TimesformerSelfAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TimesformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import av\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "frame_number = 8\n",
    "\n",
    "def extract_frames(container, frame_number):\n",
    "    stream = container.streams.video[0]\n",
    "    frame_count = stream.frames\n",
    "    \n",
    "    # Ensure we have at least {frame_number} frames in the video\n",
    "    if frame_count < frame_number:\n",
    "        raise ValueError(f\"Video must have at least {frame_number} frames.\")\n",
    "\n",
    "    frames = []\n",
    "    selected_indices = np.linspace(0, frame_count - 1, frame_number, dtype=int)\n",
    "    \n",
    "    for index in selected_indices:\n",
    "        # Seek to the desired frame\n",
    "        container.seek(int(index))\n",
    "        for frame in container.decode(video=0):\n",
    "            frame = frame.to_ndarray(format='rgb24')\n",
    "            frames.append(frame)\n",
    "            break  # Nur den ersten Frame nehmen\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base-finetuned-kinetics\")\n",
    "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\", device_map=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiwi/anaconda3/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:141: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1704987288773/work/torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  return torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "container = av.open(\"./videos/--_S9IDQPLg_000135_000145.mp4\")\n",
    "\n",
    "video = extract_frames(container, frame_number)\n",
    "\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = inputs[\"pixel_values\"].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without CUDA Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javelin throw\n",
      "Time to complete:  0.16062460699981784\n",
      "Time to complete with warmup:  0.6243631479999294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiwi/anaconda3/lib/python3.11/site-packages/torch/profiler/profiler.py:354: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n",
      "STAGE:2024-03-13 11:42:17 10755:10755 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-13 11:42:17 10755:10755 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-13 11:42:17 10755:10755 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "# warm up\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        outputs = model(inputs).logits\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "start_time1 = time.perf_counter()\n",
    "benchmark_schedule = torch.profiler.schedule(wait=0, warmup=0, active=1, repeat=1)\n",
    "with torch.no_grad(), torch.profiler.profile(\n",
    "    schedule=benchmark_schedule,\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(f'./log/rtx3080/one_video/no_cuda_graph'),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "\n",
    "    with record_function(\"model_inference\"):\n",
    "        outputs = model(inputs).logits\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    prof.step()\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "# model predicts one of the 400 Kinetics-400 classes\n",
    "predicted_label = outputs.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label])\n",
    "print(f'Time to complete:  {end_time - start_time1}')\n",
    "print(f'Time to complete with warmup:  {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with CUDA Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javelin throw\n",
      "Time to complete:  0.048468587999877855\n",
      "Time to complete with capture:  0.47260917499988864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-13 11:42:17 10755:10755 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-13 11:42:17 10755:10755 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-13 11:42:17 10755:10755 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "static_input = torch.randn(1, 8, 3, 224, 224, device=device)\n",
    "static_input.copy_(inputs)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "# warm up\n",
    "s = torch.cuda.Stream()\n",
    "s.wait_stream(torch.cuda.current_stream())\n",
    "with torch.no_grad(), torch.cuda.stream(s):\n",
    "    for i in range(10):\n",
    "        static_output = model(static_input).logits\n",
    "torch.cuda.current_stream().wait_stream(s)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# capture\n",
    "g = torch.cuda.CUDAGraph()\n",
    "with torch.cuda.graph(g):\n",
    "    static_output = model(static_input).logits\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "start_time1 = time.perf_counter()\n",
    "benchmark_schedule = torch.profiler.schedule(wait=0, warmup=0, active=1, repeat=1)\n",
    "with torch.no_grad(), torch.profiler.profile(\n",
    "    schedule=benchmark_schedule,\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(f'./log/rtx3080/one_video/cuda_graph'),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "\n",
    "    with record_function(\"data copy\"):\n",
    "        # copy data\n",
    "        static_input.copy_(inputs)\n",
    "\n",
    "    with record_function(\"model_inference\"):\n",
    "        # replay\n",
    "        g.replay()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "    prof.step()\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "\n",
    "# model predicts one of the 400 Kinetics-400 classes\n",
    "predicted_label = static_output.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label])\n",
    "print(f'Time to complete:  {end_time - start_time1}')\n",
    "print(f'Time to complete with capture:  {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = \"./videos\"\n",
    "videos = [os.path.join(folder_dir, file_name) for file_name in os.listdir(folder_dir) if file_name.endswith(\".mp4\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without CUDA Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-13 11:42:20 10755:10755 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-13 11:42:21 10755:10755 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-13 11:42:21 10755:10755 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete:  10.704028231999928\n",
      "Time to complete with capture:  11.19308719799983\n",
      "Videos processed: 50\n",
      "./videos/-1lKx46x_18_000147_000157.mp4: drumming fingers\n",
      "./videos/-0mnCHRQ-Zc_000092_000102.mp4: making bed\n",
      "./videos/-00nar1nEPc_000033_000043.mp4: playing harmonica\n",
      "./videos/-0M6S1qBn8s_000243_000253.mp4: changing oil\n",
      "./videos/-1GRj5UvVBA_000025_000035.mp4: testifying\n",
      "./videos/-0-ukHRelxA_000015_000025.mp4: petting animal (not cat)\n",
      "./videos/-1HT31BzADs_000118_000128.mp4: pole vault\n",
      "./videos/-0HRnFhCDdc_000026_000036.mp4: grooming dog\n",
      "./videos/-1mK6Npz9JA_000038_000048.mp4: playing drums\n",
      "./videos/-1IlTIWPNs4_000027_000037.mp4: shoveling snow\n",
      "./videos/-0H3T2B9PH4_000005_000015.mp4: pushing wheelchair\n",
      "./videos/-0cOo0cRVZU_000008_000018.mp4: high kick\n",
      "./videos/-0yuyrbruYM_000079_000089.mp4: flying kite\n",
      "./videos/-01cbva4erQ_000007_000017.mp4: clay pottery making\n",
      "./videos/-0R6wpipD-c_000035_000045.mp4: eating spaghetti\n",
      "./videos/-1dWGnhjB2A_000049_000059.mp4: playing ukulele\n",
      "./videos/-0JU38ZQOlY_000000_000010.mp4: bobsledding\n",
      "./videos/-1brKJdL-iM_000093_000103.mp4: golf putting\n",
      "./videos/-1KMJ1BZ2mU_000017_000027.mp4: playing didgeridoo\n",
      "./videos/-1IqhhJEfTI_000015_000025.mp4: snowkiting\n",
      "./videos/-1Kv095GbV8_000000_000010.mp4: dancing ballet\n",
      "./videos/-0MLLn0Zg1M_000015_000025.mp4: sailing\n",
      "./videos/-0aDlftNdyw_000280_000290.mp4: cutting watermelon\n",
      "./videos/-0kVxoFuMGQ_000622_000632.mp4: high kick\n",
      "./videos/-1lbeA9Jogw_000000_000010.mp4: smoking hookah\n",
      "./videos/-0LoCy0-F9A_000018_000028.mp4: hula hooping\n",
      "./videos/-0HKFF7F_BY_000003_000013.mp4: yawning\n",
      "./videos/-0MVWb7nJLY_000008_000018.mp4: slacklining\n",
      "./videos/-00fzD4K6aw_000007_000017.mp4: throwing axe\n",
      "./videos/-0oMsq-9b6c_000095_000105.mp4: sanding floor\n",
      "./videos/-1jQapks1hI_000053_000063.mp4: peeling potatoes\n",
      "./videos/-0lqH3xAz6M_000014_000024.mp4: snowkiting\n",
      "./videos/-0HSpenSJGs_000000_000010.mp4: throwing axe\n",
      "./videos/-1GUNrYsD4Y_000018_000028.mp4: feeding birds\n",
      "./videos/-0S06ntmN_I_000019_000029.mp4: shuffling cards\n",
      "./videos/-0_5tJuIrJA_000004_000014.mp4: zumba\n",
      "./videos/-0Yb1tD3HUo_000004_000014.mp4: golf putting\n",
      "./videos/-0WBheGENmk_000009_000019.mp4: golf putting\n",
      "./videos/-1B_EOupmCE_000076_000086.mp4: opening bottle\n",
      "./videos/-0WL_HWewTE_000025_000035.mp4: getting a tattoo\n",
      "./videos/-0SoxHZp0SM_000091_000101.mp4: snowboarding\n",
      "./videos/--_S9IDQPLg_000135_000145.mp4: javelin throw\n",
      "./videos/-1mbYmIZ9iw_000083_000093.mp4: breakdancing\n",
      "./videos/-0EXMXaj77A_000062_000072.mp4: feeding birds\n",
      "./videos/-01PKgtzCxc_000034_000044.mp4: diving cliff\n",
      "./videos/-1_m2Igd2Yc_000209_000219.mp4: high kick\n",
      "./videos/-0gO3FmnKD8_000135_000145.mp4: unboxing\n",
      "./videos/-1Fa5I5O_40_000009_000019.mp4: climbing a rope\n",
      "./videos/-0Y3H5y75t8_000020_000030.mp4: windsurfing\n",
      "./videos/-0MsYnGUrfE_000022_000032.mp4: archery\n"
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "count = 0\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "# warm up\n",
    "container = av.open(videos[0])\n",
    "video = extract_frames(container, frame_number)\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = inputs[\"pixel_values\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        outputs = model(inputs).logits\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "start_time1 = time.perf_counter()\n",
    "benchmark_schedule = torch.profiler.schedule(wait=5, warmup=3, active=5, repeat=1)\n",
    "with torch.no_grad(), torch.profiler.profile(\n",
    "    schedule=benchmark_schedule,\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(f'./log/rtx3080/many_videos/no_cuda_graph'),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    for i in range(len(videos)):\n",
    "        with record_function(\"open video\"):\n",
    "            container = av.open(videos[i])\n",
    "\n",
    "        with record_function(\"extract frames\"):\n",
    "            video_frames = extract_frames(container, frame_number)\n",
    "\n",
    "        with record_function(\"process frames\"):\n",
    "            inputs = image_processor(list(video_frames), return_tensors=\"pt\")\n",
    "            inputs = inputs[\"pixel_values\"].to(device)\n",
    "\n",
    "        with record_function(\"model_inference\"):\n",
    "            outputs = model(inputs).logits\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        with record_function(\"save pred\"):\n",
    "            pred[videos[i]] = model.config.id2label[outputs.argmax(-1).item()]\n",
    "\n",
    "        count += 1\n",
    "        prof.step()\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "# model predicts one of the 400 Kinetics-400 classes\n",
    "print(f'Time to complete:  {end_time - start_time1}')\n",
    "print(f'Time to complete with capture:  {end_time - start_time}')\n",
    "print(f'Videos processed: {count}')\n",
    "\n",
    "for key, value in pred.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with CUDA Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-13 11:42:31 10755:10755 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-13 11:42:32 10755:10755 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-13 11:42:32 10755:10755 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete:  10.041801956999961\n",
      "Time to complete with capture:  10.431655581999848\n",
      "Videos processed: 50\n",
      "./videos/-1lKx46x_18_000147_000157.mp4: drumming fingers\n",
      "./videos/-0mnCHRQ-Zc_000092_000102.mp4: making bed\n",
      "./videos/-00nar1nEPc_000033_000043.mp4: playing harmonica\n",
      "./videos/-0M6S1qBn8s_000243_000253.mp4: changing oil\n",
      "./videos/-1GRj5UvVBA_000025_000035.mp4: testifying\n",
      "./videos/-0-ukHRelxA_000015_000025.mp4: petting animal (not cat)\n",
      "./videos/-1HT31BzADs_000118_000128.mp4: pole vault\n",
      "./videos/-0HRnFhCDdc_000026_000036.mp4: grooming dog\n",
      "./videos/-1mK6Npz9JA_000038_000048.mp4: playing drums\n",
      "./videos/-1IlTIWPNs4_000027_000037.mp4: shoveling snow\n",
      "./videos/-0H3T2B9PH4_000005_000015.mp4: pushing wheelchair\n",
      "./videos/-0cOo0cRVZU_000008_000018.mp4: high kick\n",
      "./videos/-0yuyrbruYM_000079_000089.mp4: flying kite\n",
      "./videos/-01cbva4erQ_000007_000017.mp4: clay pottery making\n",
      "./videos/-0R6wpipD-c_000035_000045.mp4: eating spaghetti\n",
      "./videos/-1dWGnhjB2A_000049_000059.mp4: playing ukulele\n",
      "./videos/-0JU38ZQOlY_000000_000010.mp4: bobsledding\n",
      "./videos/-1brKJdL-iM_000093_000103.mp4: golf putting\n",
      "./videos/-1KMJ1BZ2mU_000017_000027.mp4: playing didgeridoo\n",
      "./videos/-1IqhhJEfTI_000015_000025.mp4: snowkiting\n",
      "./videos/-1Kv095GbV8_000000_000010.mp4: dancing ballet\n",
      "./videos/-0MLLn0Zg1M_000015_000025.mp4: sailing\n",
      "./videos/-0aDlftNdyw_000280_000290.mp4: cutting watermelon\n",
      "./videos/-0kVxoFuMGQ_000622_000632.mp4: high kick\n",
      "./videos/-1lbeA9Jogw_000000_000010.mp4: smoking hookah\n",
      "./videos/-0LoCy0-F9A_000018_000028.mp4: hula hooping\n",
      "./videos/-0HKFF7F_BY_000003_000013.mp4: yawning\n",
      "./videos/-0MVWb7nJLY_000008_000018.mp4: slacklining\n",
      "./videos/-00fzD4K6aw_000007_000017.mp4: throwing axe\n",
      "./videos/-0oMsq-9b6c_000095_000105.mp4: sanding floor\n",
      "./videos/-1jQapks1hI_000053_000063.mp4: peeling potatoes\n",
      "./videos/-0lqH3xAz6M_000014_000024.mp4: snowkiting\n",
      "./videos/-0HSpenSJGs_000000_000010.mp4: throwing axe\n",
      "./videos/-1GUNrYsD4Y_000018_000028.mp4: feeding birds\n",
      "./videos/-0S06ntmN_I_000019_000029.mp4: shuffling cards\n",
      "./videos/-0_5tJuIrJA_000004_000014.mp4: zumba\n",
      "./videos/-0Yb1tD3HUo_000004_000014.mp4: golf putting\n",
      "./videos/-0WBheGENmk_000009_000019.mp4: golf putting\n",
      "./videos/-1B_EOupmCE_000076_000086.mp4: opening bottle\n",
      "./videos/-0WL_HWewTE_000025_000035.mp4: getting a tattoo\n",
      "./videos/-0SoxHZp0SM_000091_000101.mp4: snowboarding\n",
      "./videos/--_S9IDQPLg_000135_000145.mp4: javelin throw\n",
      "./videos/-1mbYmIZ9iw_000083_000093.mp4: breakdancing\n",
      "./videos/-0EXMXaj77A_000062_000072.mp4: feeding birds\n",
      "./videos/-01PKgtzCxc_000034_000044.mp4: diving cliff\n",
      "./videos/-1_m2Igd2Yc_000209_000219.mp4: high kick\n",
      "./videos/-0gO3FmnKD8_000135_000145.mp4: unboxing\n",
      "./videos/-1Fa5I5O_40_000009_000019.mp4: climbing a rope\n",
      "./videos/-0Y3H5y75t8_000020_000030.mp4: windsurfing\n",
      "./videos/-0MsYnGUrfE_000022_000032.mp4: archery\n"
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "count = 0\n",
    "\n",
    "static_input = torch.randn(1, frame_number, 3, 224, 224, device=device)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "# warm up\n",
    "container = av.open(videos[0])\n",
    "video = extract_frames(container, frame_number)\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = inputs[\"pixel_values\"]\n",
    "static_input.copy_(inputs)\n",
    "\n",
    "s = torch.cuda.Stream()\n",
    "s.wait_stream(torch.cuda.current_stream())\n",
    "with torch.cuda.stream(s), torch.no_grad():\n",
    "    for i in range(3):\n",
    "        static_output = model(static_input).logits\n",
    "torch.cuda.current_stream().wait_stream(s)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# capture\n",
    "g = torch.cuda.CUDAGraph()\n",
    "with torch.cuda.graph(g):\n",
    "    static_output = model(static_input).logits\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "start_time1 = time.perf_counter()\n",
    "benchmark_schedule = torch.profiler.schedule(wait=5, warmup=3, active=5, repeat=1)\n",
    "with torch.no_grad(), torch.profiler.profile(\n",
    "    schedule=benchmark_schedule,\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(f'./log/rtx3080/many_videos/cuda_graph'),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    for i in range(len(videos)):\n",
    "        with record_function(\"open video\"):\n",
    "            container = av.open(videos[i])\n",
    "\n",
    "        with record_function(\"extract frames\"):\n",
    "            video = extract_frames(container, frame_number)\n",
    "\n",
    "        with record_function(\"process frames\"):\n",
    "            inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "            inputs = inputs[\"pixel_values\"]\n",
    "\n",
    "        with record_function(\"data copy\"):\n",
    "            static_input.copy_(inputs)\n",
    "\n",
    "        with record_function(\"model_inference\"):\n",
    "            g.replay()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        with record_function(\"save pred\"):\n",
    "            pred[videos[i]] = model.config.id2label[static_output.argmax(-1).item()]\n",
    "\n",
    "        count += 1\n",
    "        prof.step()\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "# model predicts one of the 400 Kinetics-400 classes\n",
    "print(f'Time to complete:  {end_time - start_time1}')\n",
    "print(f'Time to complete with capture:  {end_time - start_time}')\n",
    "print(f'Videos processed: {count}')\n",
    "for key, value in pred.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-13 11:42:41 10755:10755 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-13 11:42:42 10755:10755 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-13 11:42:42 10755:10755 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete:  8.27009914700011\n",
      "Time to complete with capture:  8.937778688000208\n",
      "Videos processed: 50\n",
      "1: drumming fingers\n",
      "2: making bed\n",
      "3: playing harmonica\n",
      "4: changing oil\n",
      "5: testifying\n",
      "6: petting animal (not cat)\n",
      "7: pole vault\n",
      "8: grooming dog\n",
      "9: playing drums\n",
      "10: shoveling snow\n",
      "11: pushing wheelchair\n",
      "12: high kick\n",
      "13: flying kite\n",
      "14: clay pottery making\n",
      "15: eating spaghetti\n",
      "16: playing ukulele\n",
      "17: bobsledding\n",
      "18: golf putting\n",
      "19: playing didgeridoo\n",
      "20: snowkiting\n",
      "21: dancing ballet\n",
      "22: sailing\n",
      "23: cutting watermelon\n",
      "24: high kick\n",
      "25: smoking hookah\n",
      "26: hula hooping\n",
      "27: yawning\n",
      "28: slacklining\n",
      "29: throwing axe\n",
      "30: sanding floor\n",
      "31: peeling potatoes\n",
      "32: snowkiting\n",
      "33: throwing axe\n",
      "34: feeding birds\n",
      "35: shuffling cards\n",
      "36: zumba\n",
      "37: golf putting\n",
      "38: golf putting\n",
      "39: opening bottle\n",
      "40: getting a tattoo\n",
      "41: snowboarding\n",
      "42: javelin throw\n",
      "43: breakdancing\n",
      "44: feeding birds\n",
      "45: diving cliff\n",
      "46: high kick\n",
      "47: unboxing\n",
      "48: climbing a rope\n",
      "49: windsurfing\n",
      "50: archery\n"
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "count = 1\n",
    "\n",
    "static_input = torch.randn(1, frame_number, 3, 224, 224, device=device)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "# warm up\n",
    "container = av.open(videos[0])\n",
    "video = extract_frames(container, frame_number)\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = inputs[\"pixel_values\"]\n",
    "static_input.copy_(inputs)\n",
    "\n",
    "s = torch.cuda.Stream()\n",
    "s.wait_stream(torch.cuda.current_stream())\n",
    "with torch.cuda.stream(s), torch.no_grad():\n",
    "    for i in range(10):\n",
    "        static_output = model(static_input).logits\n",
    "torch.cuda.current_stream().wait_stream(s)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# capture\n",
    "g = torch.cuda.CUDAGraph()\n",
    "with torch.cuda.graph(g):\n",
    "    static_output = model(static_input).logits\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "start_time1 = time.perf_counter()\n",
    "benchmark_schedule = torch.profiler.schedule(wait=5, warmup=3, active=5, repeat=1)\n",
    "with torch.no_grad(), torch.profiler.profile(\n",
    "    schedule=benchmark_schedule,\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(f'./log/rtx3080/many_videos/cuda_graph_next_video'),\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "    \n",
    "    # load first video\n",
    "    with record_function(\"open video\"):\n",
    "        container = av.open(videos[0])\n",
    "    \n",
    "    with record_function(\"extract frames\"):\n",
    "        video = extract_frames(container, frame_number)\n",
    "        \n",
    "    with record_function(\"process frames\"):\n",
    "        inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "\n",
    "    with record_function(\"data copy\"):\n",
    "        static_input.copy_(inputs[\"pixel_values\"])\n",
    "\n",
    "    for i in range(1, len(videos)):\n",
    "        with record_function(\"model_inference\"):\n",
    "            # replay\n",
    "            g.replay()\n",
    "\n",
    "        # load next video\n",
    "        with record_function(\"load next video\"):\n",
    "            with record_function(\"open video\"):\n",
    "                container = av.open(videos[i])\n",
    "\n",
    "            with record_function(\"extract frames\"):\n",
    "                video = extract_frames(container, frame_number)\n",
    "\n",
    "            with record_function(\"process frames\"):\n",
    "                inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        with record_function(\"data copy\"):\n",
    "            static_input.copy_(inputs[\"pixel_values\"])\n",
    "        \n",
    "        with record_function(\"save pred\"):\n",
    "            predicted_label = static_output.argmax(-1).item()\n",
    "            pred[count] = model.config.id2label[predicted_label]\n",
    "\n",
    "        count += 1\n",
    "        prof.step()\n",
    "    \n",
    "\n",
    "    # predict last video\n",
    "    with record_function(\"model_inference\"):\n",
    "        # replay\n",
    "        g.replay()\n",
    "\n",
    "    with record_function(\"save pred\"):\n",
    "        predicted_label = static_output.argmax(-1).item()\n",
    "        pred[count] = model.config.id2label[predicted_label]\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "# model predicts one of the 400 Kinetics-400 classes\n",
    "print(f'Time to complete:  {end_time - start_time1}')\n",
    "print(f'Time to complete with capture:  {end_time - start_time}')\n",
    "print(f'Videos processed: {count}')\n",
    "for key, value in pred.items():\n",
    "    print(f'{key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
